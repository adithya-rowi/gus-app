"""
Ragie Client - Retrieves relevant context from Gus Baha knowledge base.
Includes source metadata for citations.
"""

import os
import requests

RAGIE_API_KEY = os.environ.get("RAGIE_API_KEY")
RAGIE_BASE_URL = "https://api.ragie.ai"

# Source metadata for citations
SOURCES = {
    "gus_baha_full_transcript.txt": {
        "title": "Ngaji Penuh Humor Ilmiah Gus Baha' bersama Prof Quraish Shihab",
        "url": "https://www.youtube.com/watch?v=RHnuHSFOeNw",
        "channel": "NU Online",
        "event": "Maulid Nabi Muhammad SAW di Masjid Bayt Al-Quran, PSQ Pamulang",
        "date": "1 Oktober 2025",
        "type": "video"
    },
    "gusbaha_10_refined.md": {
        "title": "10 Ajaran Inti Gus Baha (Distilasi)",
        "url": "https://www.youtube.com/watch?v=RHnuHSFOeNw",
        "channel": "NU Online",
        "event": "Maulid Nabi Muhammad SAW di Masjid Bayt Al-Quran, PSQ Pamulang",
        "date": "1 Oktober 2025",
        "type": "summary"
    }
}


def get_source_metadata(document_name: str) -> dict:
    """Get source metadata for a document."""
    # Try exact match first
    if document_name in SOURCES:
        return SOURCES[document_name]
    
    # Try partial match
    for key, value in SOURCES.items():
        if key in document_name or document_name in key:
            return value
    
    # Default fallback
    return {
        "title": "Ceramah Gus Baha",
        "url": "https://www.youtube.com/watch?v=RHnuHSFOeNw",
        "channel": "NU Online",
        "date": "2025",
        "type": "video"
    }


def retrieve_context(query: str, top_k: int = 6) -> list[dict]:
    """
    Retrieve relevant chunks from Ragie with source metadata.
    """
    if not RAGIE_API_KEY:
        print("Warning: RAGIE_API_KEY not set")
        return []
    
    headers = {
        "Authorization": f"Bearer {RAGIE_API_KEY}",
        "Content-Type": "application/json"
    }
    
    payload = {
        "query": query,
        "top_k": top_k,
        "partition": "gus-baha"
    }
    
    try:
        response = requests.post(
            f"{RAGIE_BASE_URL}/retrievals",
            headers=headers,
            json=payload,
            timeout=10
        )
        response.raise_for_status()
        
        data = response.json()
        chunks = data.get("scored_chunks", [])
        
        results = []
        for chunk in chunks:
            doc_name = chunk.get("document_name", "unknown")
            source_meta = get_source_metadata(doc_name)
            
            results.append({
                "text": chunk.get("text", ""),
                "score": chunk.get("score", 0),
                "document_name": doc_name,
                "source": source_meta
            })
        
        return results
        
    except requests.exceptions.RequestException as e:
        print(f"Ragie retrieval error: {e}")
        return []


def format_context_for_prompt(chunks: list[dict], max_chars: int = 3000) -> str:
    """Format retrieved chunks into a context string for the LLM."""
    if not chunks:
        return ""
    
    context_parts = []
    total_chars = 0
    
    for i, chunk in enumerate(chunks, 1):
        text = chunk.get("text", "").strip()
        doc_name = chunk.get("document_name", "unknown")
        
        # Determine label
        if "10_refined" in doc_name or "ajaran" in doc_name.lower():
            label = "AJARAN INTI"
        else:
            label = "NGAJI GUS BAHA"
        
        # Truncate if too long
        if len(text) > 800:
            text = text[:800] + "..."
        
        block = f"[{label} {i}]\n{text}"
        
        if total_chars + len(block) > max_chars:
            break
            
        context_parts.append(block)
        total_chars += len(block)
    
    return "\n\n".join(context_parts)


def get_unique_sources(chunks: list[dict]) -> list[dict]:
    """Extract unique sources from chunks for citation display."""
    seen_urls = set()
    unique_sources = []
    
    for chunk in chunks:
        source = chunk.get("source", {})
        url = source.get("url", "")
        
        if url and url not in seen_urls:
            seen_urls.add(url)
            unique_sources.append({
                "title": source.get("title", "Ceramah Gus Baha"),
                "url": url,
                "channel": source.get("channel", ""),
                "date": source.get("date", ""),
                "type": source.get("type", "video")
            })
    
    return unique_sources